{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94994842-41b1-422b-9f96-bef412b49fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408a456f-7a5d-4a5a-b0c0-1512aab6ea71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git config --global user.name \"Somsubhra\"\n",
    "!git config --global user.email \"somsubhrade.04@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8426a5c7-351e-4c1a-97ab-790fc95c72e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GITHUB_USERNAME = \"somsubhra04\"\n",
    "GITHUB_PAT = \"\" #hidden\n",
    "GIT_URL_WITH_PAT = f\"https://{GITHUB_USERNAME}:{GITHUB_PAT}@github.com/{GITHUB_USERNAME}/iris-data-poisoning-wk8.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5786974c-5881-4df5-88b3-cc2038d51552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'iris-data-poisoning-wk8'...\n",
      "warning: You appear to have cloned an empty repository.\n",
      "Current working directory: /home/jupyter/iris-data-poisoning-wk8\n"
     ]
    }
   ],
   "source": [
    "!git clone https://{GITHUB_PAT}@github.com/somsubhra04/iris-data-poisoning-wk8.git\n",
    "os.chdir('iris-data-poisoning-wk8')\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ce5607-db3e-4a28-8155-a9c4553afa3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_VERSION = \"v1\"\n",
    "DATA_FILE_NAME = f'../week1/data/iris{DATA_VERSION}.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_FILE_NAME)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {DATA_FILE_NAME}. Please check the path.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd7136fd-7f40-406c-8c31-f4f5094efdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.8          4.0           1.2          0.2     setosa\n",
       "1             5.7          4.4           1.5          0.4     setosa\n",
       "2             5.4          3.9           1.3          0.4     setosa\n",
       "3             5.1          3.5           1.4          0.3     setosa\n",
       "4             5.7          3.8           1.7          0.3     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "96            6.7          3.0           5.2          2.3  virginica\n",
       "97            6.3          2.5           5.0          1.9  virginica\n",
       "98            6.5          3.0           5.2          2.0  virginica\n",
       "99            6.2          3.4           5.4          2.3  virginica\n",
       "100           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[101 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8af58d8-ef24-484c-aeec-652bd3b7310c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from: ../week1/data/irisv1.csv\n",
      "Clean Training Set Size: 80\n",
      "Clean Test Set Size: 21\n"
     ]
    }
   ],
   "source": [
    "# Separating features (X) and target (y)\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y_species = df['species']\n",
    "\n",
    "# Encoding the categorical 'species' column into numerical target labels (0, 1, 2)\n",
    "le = LabelEncoder()\n",
    "y = pd.Series(le.fit_transform(y_species))\n",
    "\n",
    "# getting feature statistics for generating random poison data\n",
    "X_min = X.min().values\n",
    "X_max = X.max().values\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "# Splitting data: Training set will be poisoned, Test set remains clean for validation\n",
    "X_clean_train, X_test, y_clean_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Data successfully loaded from: {DATA_FILE_NAME}\")\n",
    "print(f\"Clean Training Set Size: {len(X_clean_train)}\")\n",
    "print(f\"Clean Test Set Size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5655573-9796-416a-be64-a8bfc9403866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Data Poisoning Function ---\n",
    "def generate_poisoned_data(X_base, y_base, poisoning_level):\n",
    "    \"\"\"\n",
    "    Generates non-targeted, availability-style poisoned data.\n",
    "    The poisoning method injects synthetic, randomly-labeled samples.\n",
    "    \"\"\"\n",
    "    N_base = len(X_base)\n",
    "    N_poison = int(N_base * poisoning_level / (1 - poisoning_level))\n",
    "    \n",
    "    if N_poison == 0:\n",
    "        return X_base, y_base, 0 # Return clean data if poisoning size is zero\n",
    "\n",
    "    # Generating synthetic features: random floats within the min/max range\n",
    "    X_poison_list = []\n",
    "    for i in range(len(X_base.columns)):\n",
    "        # np.random.uniform(low, high, size)\n",
    "        features = np.random.uniform(X_min[i], X_max[i], N_poison)\n",
    "        X_poison_list.append(features)\n",
    "        \n",
    "    X_poison = pd.DataFrame(np.column_stack(X_poison_list), columns=X_base.columns)\n",
    "    \n",
    "    # Generating random labels for maximum confusion (non-targeted attack)\n",
    "    y_poison = pd.Series(np.random.randint(0, n_classes, N_poison))\n",
    "    \n",
    "    # Concatenating clean training data and poisoned data\n",
    "    X_poisoned = pd.concat([X_base, X_poison], ignore_index=True)\n",
    "    y_poisoned = pd.concat([y_base, y_poison], ignore_index=True)\n",
    "    \n",
    "    # Sanity check: Ensure the total size is correct\n",
    "    actual_poisoning_percentage = N_poison / len(X_poisoned)\n",
    "    \n",
    "    return X_poisoned, y_poisoned, actual_poisoning_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d7d9db9-27e1-4778-a7ac-f37fc40344fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 09:24:42 INFO mlflow.tracking.fluent: Experiment with name 'IRIS-Data-Poisoning-Attack' does not exist. Creating a new experiment.\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "2025/11/10 09:24:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/11/10 09:24:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "2025/11/10 09:24:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run '0Pct_Poisoning' completed. Validation Accuracy: 0.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/10 09:25:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "2025/11/10 09:25:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run '5Pct_Poisoning' completed. Validation Accuracy: 0.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/10 09:25:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run '10Pct_Poisoning' completed. Validation Accuracy: 0.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 09:25:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/11/10 09:25:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run '50Pct_Poisoning' completed. Validation Accuracy: 0.9048\n",
      "\n",
      "All experiments completed. Check the 'mlruns' directory for data.\n"
     ]
    }
   ],
   "source": [
    "# --- MLflow Experiment Loop ---\n",
    "mlflow.set_experiment(\"IRIS-Data-Poisoning-Attack\")\n",
    "\n",
    "# Poisoning levels to test (Target percentage of the final training dataset)\n",
    "POISONING_LEVELS = [0.0, 0.05, 0.10, 0.50]\n",
    "\n",
    "for level in POISONING_LEVELS:\n",
    "    run_name = f\"{int(level*100)}Pct_Poisoning\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        \n",
    "        # 1. Generating Poisoned Data\n",
    "        X_train_p, y_train_p, actual_p = generate_poisoned_data(\n",
    "            X_clean_train, y_clean_train, level\n",
    "        )\n",
    "        \n",
    "        # 2. Logging Parameters\n",
    "        mlflow.log_param(\"poisoning_level_target\", level)\n",
    "        mlflow.log_param(\"actual_poisoning_ratio\", f\"{actual_p:.4f}\")\n",
    "        mlflow.log_param(\"training_set_size\", len(X_train_p))\n",
    "        mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "        \n",
    "        # 3. Training Model\n",
    "        model = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=200, random_state=42)\n",
    "        model.fit(X_train_p, y_train_p)\n",
    "        \n",
    "        # 4. Evaluating on Clean Test Data\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # 5. Logging Metrics and Model\n",
    "        mlflow.log_metric(\"validation_accuracy\", accuracy)\n",
    "        \n",
    "        # Logging the model (artifact)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"Run '{run_name}' completed. Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nAll experiments completed. Check the 'mlruns' directory for data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f411f0a-e1d3-4eb1-a17c-808ca29cf210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pushing to GitHub ---\n",
      "On branch master\n",
      "Your branch is based on 'origin/master', but the upstream is gone.\n",
      "  (use \"git branch --unset-upstream\" to fixup)\n",
      "\n",
      "nothing to commit, working tree clean\n",
      "Enumerating objects: 96, done.\n",
      "Counting objects: 100% (96/96), done.\n",
      "Delta compression using up to 2 threads\n",
      "Compressing objects: 100% (63/63), done.\n",
      "Writing objects: 100% (96/96), 10.13 KiB | 211.00 KiB/s, done.\n",
      "Total 96 (delta 14), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (14/14), done.\u001b[K\n",
      "To https://github.com/somsubhra04/iris-data-poisoning-wk8.git\n",
      " * [new branch]      main -> main\n",
      "Branch 'main' set up to track remote branch 'main' from 'https://somsubhra04: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@github.com/somsubhra04/iris-data-poisoning-wk8.git'.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Pushing to GitHub ---\")\n",
    "!git add .\n",
    "!git commit -m \"Logged four MLflow runs for 0, 5, 10, and 50 percent data poisoning.\"\n",
    "!git branch -M main\n",
    "!git push -u {GIT_URL_WITH_PAT} main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d55f4f2a-f322-4f31-bc67-9e30b78d3a11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/jupyter\n"
     ]
    }
   ],
   "source": [
    "# Come back to the repository root\n",
    "os.chdir('..')\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3103a-89bb-41bd-8bf9-e660d211d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Pushing to GitHub ---\")\n",
    "!git add wk8.ipynb\n",
    "!git commit -m \"pushed the notebook\"\n",
    "!git branch -M main\n",
    "!git push -u {GIT_URL_WITH_PAT} main"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
